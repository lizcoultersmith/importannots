{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Set-up MTURK: \n",
    "\n",
    "an explanation of how AWS credential files work https://docs.aws.amazon.com/sdk-for-php/v3/developer-guide/guide_credentials_profiles.html\n",
    "(This says it's for the php sdk, but the credential file works the same for Python)\n",
    "other resources:\n",
    "https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html\n",
    "https://docs.aws.amazon.com/cli/latest/topic/config-vars.html\n",
    "\n",
    "In summary:\n",
    "\n",
    "edit the file ~/.aws/config to add your username profile. There are two ways to do this:\n",
    "(1) directly edit ~/.aws/config or\n",
    "(2) run: aws configure --profile \"your username\"\n",
    "(prereq: pip install awscli)\n",
    "\n",
    "A sample config file for reference: \n",
    " output=json\n",
    " region=us-east-1\n",
    " aws_access_key_id=foo\n",
    " aws_secret_access_key=bar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Zoya's notes (sources for this file):\n",
    "(Anelise) https://github.com/a-newman/mturk-template/blob/master/mturk/mturk.ipynb\n",
    "(Camilo) https://github.com/diviz-mit/predimportance/blob/master/notebooks/mturk_handler_importance_labeling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the config file (see example). \n",
    "# will work with a config file for https://github.com/kimberli/mturk-template, \n",
    "# but a minimal example is included.\n",
    "# Also supports an additional feature, the \"variants\" key, which is a list of dictionaries. \n",
    "# If \"variants\" is specified, for each dictionary it contains, those keys will be meshed with the \"hitCreation\"\n",
    "# key and one task will be made per variant. Else, config[\"hitCreation\"][\"numTasks\"] versions of the same\n",
    "# task will be launched. \n",
    "CONFIG_PATH = \"./config.json\"\n",
    "\n",
    "# where to save downloaded results \n",
    "SAVE_PATH = \".\"\n",
    "# Path to the html task\n",
    "TASK_PATH = \".\"\n",
    "\n",
    "# where to save downloaded results \n",
    "SAVE_PATH = \"./result.csv\" \n",
    "\n",
    "# Whether to launch a hit per fold.txt in folder \"files\"\n",
    "LAUNCH_HITS_FOR_ALL_FOLDS = False\n",
    "FOLD_REQ_STR = 'poster_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SANDBOX\n",
      "TASK URL: https://cfosco.github.io/mturk-importance/?url=natimgs35_0.txt\n"
     ]
    }
   ],
   "source": [
    "from boto3 import client\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "_USING_PROD = None\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "    hit_config = config['hitCreation']\n",
    "\n",
    "if hit_config['production']:\n",
    "    print(\"USING PROD\")\n",
    "    _USING_PROD = True\n",
    "    endpoint_url = 'https://mturk-requester.us-east-1.amazonaws.com'\n",
    "else:\n",
    "    print(\"USING SANDBOX\")\n",
    "    _USING_PROD = False\n",
    "    endpoint_url = 'https://mturk-requester-sandbox.us-east-1.amazonaws.com'\n",
    "        \n",
    "cl = client('mturk', region_name='us-east-1', endpoint_url=endpoint_url)\n",
    "\n",
    "if hit_config['fold']:\n",
    "    hit_config['taskUrl'] = hit_config['taskUrl'] + \"?url=%s\" % hit_config['fold']\n",
    "elif fld:\n",
    "    hit_config['taskUrl'] = fld\n",
    "else:\n",
    "    fld = input('Define fold (input name+.txt)')\n",
    "    hit_config['taskUrl'] = hit_config['taskUrl'] + \"?url=%s\" % fld\n",
    "\n",
    "if LAUNCH_HITS_FOR_ALL_FOLDS:\n",
    "    all_folds = [f for f in os.listdir(os.path.join(TASK_PATH,'files')) if FOLD_REQ_STR in f]        \n",
    "    print('Using folds:',all_folds)\n",
    "    \n",
    "print(\"TASK URL:\", hit_config['taskUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety flags that prevent you from accidentally messing up your HITs. \n",
    "# Set to False except when you are performing these specific tasks. \n",
    "ALLOW_HIT_CREATION = True\n",
    "ALLOW_ASSIGNMENT_ADDITION = False\n",
    "ALLOW_CREATE_QUAL = True\n",
    "ALLOW_UPDATE_EXPIRATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of qualifications that you will use to filter potential workers. \n",
    "# These require that workers come from the US and have an approval rating >= 95%\n",
    "QUALS = [\n",
    "       {\n",
    "           'QualificationTypeId': '00000000000000000071',\n",
    "           'Comparator': 'EqualTo',\n",
    "           'LocaleValues': [{\n",
    "               'Country': 'US',\n",
    "           }],\n",
    "       },\n",
    "        \n",
    "       {\n",
    "           'QualificationTypeId': '000000000000000000L0',\n",
    "           'Comparator': 'GreaterThanOrEqualTo',\n",
    "           'IntegerValues': [\n",
    "               95\n",
    "           ],\n",
    "       },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a HIT in the form of an External Question inside an iFrame\n",
    "def create_hit(task):\n",
    "    questionText = \"<ExternalQuestion xmlns=\\\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/\"\n",
    "    questionText += \"2006-07-14/ExternalQuestion.xsd\\\">\\n<ExternalURL>\" + task['taskUrl']\n",
    "    questionText += \"</ExternalURL>\\n  <FrameHeight>700</FrameHeight>\\n</ExternalQuestion>\"\n",
    "\n",
    "    response = cl.create_hit(\n",
    "        MaxAssignments=task['numAssignments'],\n",
    "        AutoApprovalDelayInSeconds=604800,\n",
    "        LifetimeInSeconds=task['lifetime'],\n",
    "        AssignmentDurationInSeconds=task['duration'],\n",
    "        Reward=task['rewardAmount'],\n",
    "        Title=task['title'],\n",
    "        Keywords=task['keywords'],\n",
    "        Description=task['description'],\n",
    "        Question=questionText,\n",
    "        QualificationRequirements=QUALS,\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Helpers for creating HITs. \n",
    "\n",
    "# generic helper that sets metadata fields based on the config file.\n",
    "def create_hit(task, questionText, quals=QUALS): \n",
    "    response = cl.create_hit(\n",
    "        MaxAssignments=task['numAssignments'],\n",
    "        AutoApprovalDelayInSeconds=604800,\n",
    "        LifetimeInSeconds=task['lifetime'],\n",
    "        AssignmentDurationInSeconds=task['duration'],\n",
    "        Reward=task['rewardAmount'],\n",
    "        Title=task['title'],\n",
    "        Keywords=task['keywords'],\n",
    "        Description=task['description'],\n",
    "        Question=questionText,\n",
    "        QualificationRequirements=quals,\n",
    "    )\n",
    "    print(response)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# creates a HIT in the form of an External Question inside an iFrame\n",
    "def create_hit_iframe(task):\n",
    "    questionText = \"<ExternalQuestion xmlns=\\\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/\"\n",
    "    questionText += \"2006-07-14/ExternalQuestion.xsd\\\">\\n<ExternalURL>\" + task['taskUrl']\n",
    "    questionText += \"</ExternalURL>\\n  <FrameHeight>700</FrameHeight>\\n</ExternalQuestion>\"\n",
    "    create_hit(task, questionText)\n",
    "    \n",
    "# Helper to create a HIT in the form of a simple UI with a link to an external page and an\n",
    "# input box for a completion code \n",
    "def create_hit_external(task):\n",
    "    with open('questionform_template.xml', 'r') as myfile:\n",
    "        template=myfile.read() \n",
    "    question_xml = template % (hit_config[\"title\"], hit_config[\"description\"], hit_url)\n",
    "    create_hit(task, question_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 1 tasks\n",
      "{'HIT': {'HITId': '3K2CEDRACBAL2FEQUFGVMBI09CFMTA', 'HITTypeId': '30NHI4EO3UD99GICXIW3TB0XNEGBTG', 'HITGroupId': '35VN5BQM7UBVL5VR9SWFEM6SUT0J5Q', 'CreationTime': datetime.datetime(2019, 5, 13, 17, 24, 7, tzinfo=tzlocal()), 'Title': 'Annotate the most important regions on graphic designs', 'Description': 'Manually highlight the important parts of a graphic design. You will be shown a set of 10 to 15 images, and you will have to indicate which parts feel important to you.', 'Question': '<ExternalQuestion xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2006-07-14/ExternalQuestion.xsd\">\\n<ExternalURL>https://cfosco.github.io/mturk-importance/?url=natimgs35_0.txt</ExternalURL>\\n  <FrameHeight>700</FrameHeight>\\n</ExternalQuestion>', 'Keywords': 'labeling, importance, highlighting, graphic, designs, images', 'HITStatus': 'Assignable', 'MaxAssignments': 1, 'Reward': '0.85', 'AutoApprovalDelayInSeconds': 604800, 'Expiration': datetime.datetime(2019, 5, 15, 21, 10, 47, tzinfo=tzlocal()), 'AssignmentDurationInSeconds': 1200, 'QualificationRequirements': [{'QualificationTypeId': '00000000000000000071', 'Comparator': 'EqualTo', 'LocaleValues': [{'Country': 'US'}], 'RequiredToPreview': False, 'ActionsGuarded': 'Accept'}, {'QualificationTypeId': '000000000000000000L0', 'Comparator': 'GreaterThanOrEqualTo', 'IntegerValues': [95], 'RequiredToPreview': False, 'ActionsGuarded': 'Accept'}], 'HITReviewStatus': 'NotReviewed', 'NumberOfAssignmentsPending': 0, 'NumberOfAssignmentsAvailable': 1, 'NumberOfAssignmentsCompleted': 0}, 'ResponseMetadata': {'RequestId': '3db5f171-49c9-4492-b59b-53cbdff1f560', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3db5f171-49c9-4492-b59b-53cbdff1f560', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1408', 'date': 'Tue, 14 May 2019 00:24:06 GMT'}, 'RetryAttempts': 0}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if ALLOW_HIT_CREATION: \n",
    "    if config.get('variants', None): \n",
    "        print(\"creating \" + str(len(config['variants'])) + \" variants\")\n",
    "        for var in config['variants']: \n",
    "            task = copy.deepcopy(config)\n",
    "            task.update(var)\n",
    "            create_hit(task)\n",
    "    \n",
    "    elif LAUNCH_HITS_FOR_ALL_FOLDS:\n",
    "        print(\"creating\", len(all_folds), \"tasks\")\n",
    "        for fold in all_folds:\n",
    "            hit_config['taskUrl'] = hit_config['taskUrl'].split('?')[0] + \"?url=%s\" % fold\n",
    "            create_hit(hit_config)\n",
    "    else:\n",
    "        print(\"creating \" + str(hit_config['numTasks']) + \" tasks\")\n",
    "        for i in range(hit_config['numTasks']):\n",
    "            #create_hit(hit_config)\n",
    "            create_hit_iframe(hit_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIT MONITORING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contacts MTurk API to get all assignments for a HIT\n",
    "# Returns them in a list. \n",
    "def get_all_assignments(hitid): \n",
    "    assignments = []\n",
    "    should_continue = True\n",
    "    next_token = False\n",
    "    while (should_continue): \n",
    "        args = {\n",
    "            'HITId': hitid, \n",
    "            'MaxResults': 100\n",
    "        }\n",
    "        if (next_token): \n",
    "            args['NextToken'] = next_token\n",
    "        r = cl.list_assignments_for_hit(**args)\n",
    "        next_token = r.get('NextToken', False)\n",
    "        assignments.extend(r[\"Assignments\"])\n",
    "        should_continue = len(r[\"Assignments\"]) > 0\n",
    "    return assignments\n",
    "\n",
    "\n",
    "def get_hits(max_results=200):\n",
    "    hits = []\n",
    "    mr = min(max_results, 100)\n",
    "    should_continue = True\n",
    "    next_token=False\n",
    "    c=0\n",
    "    while(should_continue):\n",
    "        args = {\n",
    "            'MaxResults': mr\n",
    "        }\n",
    "        if (next_token): \n",
    "            args['NextToken'] = next_token\n",
    "        r = cl.list_hits(**args)\n",
    "        next_token = r.get('NextToken', False)\n",
    "        hits.extend(r[\"HITs\"])\n",
    "        c += len(r[\"HITs\"])\n",
    "        should_continue = next_token and (c<max_results)\n",
    "#         mr = mr-100\n",
    "    return hits\n",
    "\n",
    "# Summarizes all hits in `hits` in a human-readable way. \n",
    "# Prints out the HIT Title, id, if it is expired, and how many assignments it has\n",
    "# completed, pending, and left for work. \n",
    "def summarize_hits(hits, get_submitted=True): \n",
    "    print(len(hits))\n",
    "    ret = \"\"\n",
    "    for hit in hits: \n",
    "        expiration = hit['Expiration'].replace(tzinfo=None)\n",
    "        is_expired = expiration < datetime.datetime.now()\n",
    "        description = (\"Title: {title}\\n\" \n",
    "        \"ID: {hid}\\n\"\n",
    "        \"\\tAssignments left: {left}\\n\"\n",
    "        \"\\tAssignments completed: {complete}\\n\"\n",
    "        \"\\tAssignments pending: {pending}\\n\"\n",
    "        ).format(\n",
    "            title=hit['Title'], \n",
    "            hid=hit['HITId'], \n",
    "            left=hit['NumberOfAssignmentsAvailable'], \n",
    "            complete=hit['NumberOfAssignmentsCompleted'], \n",
    "            pending=hit['NumberOfAssignmentsPending']\n",
    "            \n",
    "        )\n",
    "        \n",
    "        if get_submitted:\n",
    "            submitted=0\n",
    "            assignments = get_all_assignments(hit['HITId'])\n",
    "            if assignments:\n",
    "                for a in assignments: \n",
    "                    if a['AssignmentStatus'] == 'Submitted':\n",
    "                        submitted+=1\n",
    "                    \n",
    "            description+='\\tAssignments submitted: %d\\n' % submitted\n",
    "        \n",
    "        description += \"\\tExpired: {exp}\\n\\n\".format(exp=str(is_expired))\n",
    "        \n",
    "        ret += description\n",
    "    print(ret)\n",
    "    \n",
    "# Prints a human-readable summary of all pending/submitted/approved assignments for all hits in `hits`\n",
    "def summarize_assignments(hits):\n",
    "    ret = \"\"\n",
    "    for hit in hits: \n",
    "        hid = hit['HITId']\n",
    "        title =  hit['Title']\n",
    "        name = \"HIT %s: %s\" % (hid, title)\n",
    "        ret += name + \"\\n\"\n",
    "        assignments = get_all_assignments(hid)\n",
    "        if len(assignments) == 0: \n",
    "            ret += \"\\tNo pending/submitted/approved assignments for this HIT\\n\"\n",
    "        for a in assignments: \n",
    "            desc = \"\\tAssignment {aid}\\n\\t\\tStatus: {status}\\n\".format(aid=a['AssignmentId'], status=a['AssignmentStatus'])\n",
    "            ret += desc\n",
    "    print(ret)\n",
    "    \n",
    "# Refreshes data about the requested hits\n",
    "def refresh_hits(): \n",
    "    global hits \n",
    "    global MAX_RESULTS\n",
    "    hits = cl.list_hits(MaxResults=MAX_RESULTS)['HITs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call to grab HIT data from MTurk \n",
    "hits = get_hits(max_results=30)\n",
    "print(len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes all outstanding HITs\n",
    "# refresh_hits()\n",
    "summarize_hits(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROVE HITS ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve_all(hits): \n",
    "    num_approved = 0\n",
    "    for hit in hits: \n",
    "        # make sure you keep getting assignments \n",
    "        assignments = get_all_assignments(hit[\"HITId\"])\n",
    "        #print(assignments)\n",
    "        for a in assignments: \n",
    "            if a['AssignmentStatus'] != 'Approved':\n",
    "                print(\"Approving assignment\")\n",
    "                num_approved += 1\n",
    "                cl.approve_assignment(AssignmentId=a['AssignmentId'])\n",
    "    print(\"Approved %d assignments\" % num_approved)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
